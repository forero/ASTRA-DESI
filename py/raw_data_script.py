# -*- coding: utf-8 -*-
"""Raw_data_script

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rn7tw2LayYu6Ta9SCUc2t27aHYF1Q_Xo
"""

# -*- coding: utf-8 -*-
"""Raw_data_script

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rn7tw2LayYu6Ta9SCUc2t27aHYF1Q_Xo
"""

import os
import pandas as pd
import numpy as np
from astropy.io import fits
from astropy.coordinates import SkyCoord
from astropy.cosmology import Planck18
import astropy.units as u
from io import BytesIO
import requests

# Parameters
base_url = "https://data.desi.lbl.gov/public/edr/vac/edr/lss/v2.0/LSScats/clustering/"
tracers = ['BGS_ANY', 'ELG', 'LRG', 'QSO']
real_suffix = {'N': '_N_clustering.dat.fits', 'S': '_S_clustering.dat.fits'}
random_suffix = {'N': '_N_{}_clustering.ran.fits', 'S': '_S_{}_clustering.ran.fits'}
n_random_files = 18
selected_columns = ['TARGETID', 'ROSETTE_NUMBER', 'RA', 'DEC', 'Z']
output_dir = "01_CREATE_RAW"
os.makedirs(output_dir, exist_ok=True)

def load_fits_file_from_url(url, columns):
    with fits.open(BytesIO(requests.get(url).content)) as hdul:
        data = hdul[1].data
        df = pd.DataFrame({
            col: data[col].byteswap().view(data[col].dtype.newbyteorder()) if data[col].dtype.byteorder not in ('=', '|') else data[col]
            for col in columns
        })
        df = df.rename(columns={'ROSETTE_NUMBER': 'ZONE'})
        return df

def compute_cartesian(df):
    df = df.copy()
    comoving_distance = Planck18.comoving_distance(df['Z'].values)
    coords = SkyCoord(ra=df['RA'].values * u.deg, dec=df['DEC'].values * u.deg, distance=comoving_distance)
    df['X_CART'] = coords.cartesian.x.value
    df['Y_CART'] = coords.cartesian.y.value
    df['Z_CART'] = coords.cartesian.z.value
    return df

def process_real(tracer, zone):
    dfs = []
    for hemi in ['N', 'S']:
        url = base_url + tracer + real_suffix[hemi]
        df = load_fits_file_from_url(url, selected_columns)
        df = df[df['ZONE'] == zone]
        dfs.append(df)
    df = pd.concat(dfs, ignore_index=True)
    df = compute_cartesian(df)
    df['TRACERTYPE'] = tracer + "_DATA"
    df['RANDITER'] = -1
    return df

def process_random(tracer, zone):
    dfs = []

    for hemi in ['N', 'S']:
        ran_urls = [base_url + tracer + f"_{hemi}_{i}_clustering.ran.fits" for i in range(18)]
        for url in ran_urls:
            df = load_fits_file_from_url(url, selected_columns)
            df = df[df['ZONE'] == zone]  # Filter by zone
            df['HEMI'] = hemi
            dfs.append(df)

    full_df = pd.concat(dfs, ignore_index=True)
    
    all_randoms = []

    # Iterate over unique rosettes in this zone
    for rosetta in full_df['ZONE'].unique():
        rosetta_df = full_df[full_df['ZONE'] == rosetta]

        n_rows = len(rosetta_df)
        if n_rows == 0:
            continue

        for j in range(100):
            sample_df = rosetta_df.sample(n=n_rows, random_state=j).reset_index(drop=True)
            sample_df = compute_cartesian(sample_df)
            sample_df['TRACERTYPE'] = tracer + "_RANDOM"
            sample_df['RANDITER'] = j
            all_randoms.append(sample_df)

    final_df = pd.concat(all_randoms, ignore_index=True)
    return final_df

for zone in range(20):
    all_dfs = []
    for tracer in tracers:
        real = process_real(tracer, zone)     # returns real data (N + S) for the zone
        random = process_random(tracer, zone) # returns 100x random samples for the zone
        all_dfs.extend([real, random])
    
    combined = pd.concat(all_dfs, ignore_index=True)

    # Final column order
    combined = combined[['TARGETID', 'TRACERTYPE', 'RANDITER', 'RA', 'DEC', 'Z', 'X_CART', 'Y_CART', 'Z_CART']]

    # Save to compressed FITS
    output_path = os.path.join(output_dir, f"ZONE_{zone:02d}.fits.gz")
    fits.writeto(output_path, combined.to_records(index=False), overwrite=True)
